{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Reconstructing the path\n",
    "\n",
    "In this assignment you will use Spark to compute the shortest path between two vertices. In the video, you have learned how to compute the distances between a source vertex and all other vertices in a graph. Now, your task is to reconstruct the shortest path, that is a sequence of vertices connected by the edges.\n",
    "\n",
    "Dataset location: */data/twitter/twitter_sample_small.txt*\n",
    "\n",
    "Format: `user_id \\t follower_id`\n",
    "\n",
    "Your task is to find the shortest path between vertices 12 and 34. In case of multiple shortest paths (that is, disjoint paths with the same length), any will suffice. Output format is the sequence of vertices, delimited by a comma, without spaces. For example, the path `12 -> 42 -> 34` should be printed as:\n",
    "\n",
    "```\n",
    "12,42,34\n",
    "```\n",
    "\n",
    "The result on the sample dataset:\n",
    "\n",
    "```\n",
    "12,422,53,52,107,20,23,274,34\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1. Create SparkContext."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"yarn\"))\n",
    "\n",
    "# For local run uncomment the lines below.\n",
    "# sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"local\"))\n",
    "# sc.uiWebUrl"
   ]
  },
  {
   "source": [
    "### Step 2. BFS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For remote run\n",
    "DATA_FILE = \"/data/twitter/twitter_sample_small.txt\"\n",
    "\n",
    "# For local run\n",
    "# DATA_FILE = \"twitter_sample_small.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_edge(s):\n",
    "    \"\"\"\n",
    "    Parses an edge to the format (<follower>, (<user>, <parent>)).\n",
    "\n",
    "    Note, that <parent> is always -1.\n",
    "    \"\"\"\n",
    "    user, follower = s.split(\"\\t\")\n",
    "    return (int(follower), (int(user), -1))\n",
    "\n",
    "\n",
    "def prepare_step(item):\n",
    "    \"\"\"\n",
    "    Parses an edge possible way (edge + parent + neighbour).\n",
    "    \"\"\"\n",
    "    follower, distance, neighbour = item[0], item[1][0][0], item[1][1][0]\n",
    "    return (neighbour, (distance, follower))\n",
    "\n",
    "\n",
    "def make_step(item):\n",
    "    \"\"\"\n",
    "    Recalculates existed distance for a step and complete it.\n",
    "    \"\"\"\n",
    "    user, old_step, new_step = item[0], item[1][0], item[1][1]\n",
    "    if old_step:\n",
    "        return (user, old_step)\n",
    "    else:\n",
    "        return (user, (new_step[0] + 1, new_step[1]))\n",
    "\n",
    "\n",
    "def bfs(start, num_partitions=4):\n",
    "    \"\"\"\n",
    "    Performs a breadth-first search across the graph from specified vertex.\n",
    "\n",
    "    :return: a list of traversed vertexes in format: \n",
    "             [(<vertex>, (<distance>, <parent>))]\n",
    "    \"\"\"\n",
    "    edges = sc.textFile(DATA_FILE).map(parse_edge).cache()\n",
    "\n",
    "    current_distance = 0\n",
    "    distances = sc.parallelize([(start, (current_distance, -1))]).partitionBy(num_partitions)\n",
    "\n",
    "    while True:\n",
    "        candidates = distances.join(edges, num_partitions).map(prepare_step)\n",
    "        new_distances = distances.fullOuterJoin(candidates, num_partitions).map(make_step).distinct().persist()\n",
    "\n",
    "        updated_distances_count = new_distances.filter(lambda i: i[1][0] == current_distance + 1).count()\n",
    "        if updated_distances_count > 0:\n",
    "            current_distance += 1\n",
    "            distances = new_distances\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return distances\n"
   ]
  },
  {
   "source": [
    "### Step 3. Reconstruct the path."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_path(traverse_table, start, end):\n",
    "    \"\"\"\n",
    "    Builds a path from the start to the end from\n",
    "    the traverse table which has the format:\n",
    "    [(<vertex>, (<distance>, <parent>))] .\n",
    "\n",
    "    :return: a path as a comma-separated string\n",
    "    \"\"\"\n",
    "    path = []\n",
    "    parent = end\n",
    "\n",
    "    while parent != start and parent != -1:\n",
    "        current_step = traverse_table.filter(lambda x: x[0] == parent).collect()\n",
    "        path.append(parent)\n",
    "        parent = int(current_step[0][1][1])\n",
    "\n",
    "    if parent == -1:\n",
    "        return \"\"\n",
    "\n",
    "    path.append(start)\n",
    "    return \",\".join(list(map(str, path[::-1])))"
   ]
  },
  {
   "source": [
    "### Step 4. Find the shortest path."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 12\n",
    "end = 34\n",
    "\n",
    "traverse_table = bfs(start).cache()\n",
    "print(reconstruct_path(traverse_table, start, end))"
   ]
  },
  {
   "source": [
    "### Step 5. Free SparkContext."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ]
}